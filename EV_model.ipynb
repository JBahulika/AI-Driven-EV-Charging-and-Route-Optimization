{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: folium in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: branca>=0.6.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from folium) (0.8.2)\n",
      "Requirement already satisfied: requests in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from folium) (2.32.5)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from folium) (3.1.6)\n",
      "Requirement already satisfied: xyzservices in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from folium) (2025.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2>=2.9->folium) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->folium) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->folium) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->folium) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bahulika/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->folium) (3.11)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "All libraries installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Install all necessary libraries ---\n",
    "!pip install pandas numpy matplotlib seaborn folium scikit-learn joblib\n",
    "\n",
    "# --- 2. Import all libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import folium.plugins\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Import scikit-learn (sklearn) components\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Ignore warnings for a cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries installed and imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Cleaning 'ev-charging-stations-india.csv' ---\n",
      "--- Success: 'df_stations_clean' created with 1529 rows. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Cleaning 'ev-charging-stations-india.csv' ---\")\n",
    "\n",
    "# --- 1. Load Station Data ---\n",
    "station_data_url = 'https://raw.githubusercontent.com/JBahulika/AI-Driven-EV-Charging-and-Route-Optimization/main/Data/ev-charging-stations-india.csv'\n",
    "df_stations = pd.read_csv(station_data_url)\n",
    "\n",
    "# --- 2. Fix 'lattitude' (typo and data type) ---\n",
    "# Drop rows with no coordinates\n",
    "df_stations_clean = df_stations.dropna(subset=['lattitude', 'longitude'])\n",
    "# Coerce bad text to 'NaN'\n",
    "df_stations_clean['lattitude'] = pd.to_numeric(df_stations_clean['lattitude'], errors='coerce')\n",
    "# Drop any new NaN rows\n",
    "df_stations_clean = df_stations_clean.dropna(subset=['lattitude'])\n",
    "# Rename column\n",
    "df_stations_clean = df_stations_clean.rename(columns={'lattitude': 'latitude'})\n",
    "\n",
    "# --- 3. Filter Coordinate Outlier ---\n",
    "# Remove the row with the impossible longitude\n",
    "df_stations_clean = df_stations_clean[df_stations_clean['longitude'] <= 180]\n",
    "\n",
    "# --- 4. Clean and Standardize 'state' Column ---\n",
    "# This map fixes all cities-as-states and typos we found\n",
    "state_cleaning_map = {\n",
    "    'Telengana': 'Telangana', 'Tamilnadu': 'Tamil Nadu', 'Taminadu': 'Tamil Nadu',\n",
    "    'Maharashra': 'Maharashtra', 'Westbengal': 'West Bengal', 'Uttrakhand': 'Uttarakhand',\n",
    "    'Uttarkhand': 'Uttarakhand', 'Harayana': 'Haryana', 'Karala': 'Kerala',\n",
    "    'Chattisgarh': 'Chhattisgarh', 'Jammu & Kashmir': 'Jammu and Kashmir',\n",
    "    'Jammu': 'Jammu and Kashmir', 'Pondicherry': 'Puducherry', 'Andra Pradesh': 'Andhra Pradesh',\n",
    "    'Andhrapradesh': 'Andhra Pradesh', 'Andhra Pradesh ': 'Andhra Pradesh',\n",
    "    'Andaman': 'Andaman and Nicobar Island', 'Hyderabad': 'Telangana',\n",
    "    'Hyderabadu00A0': 'Telangana', 'Rajahmundry': 'Andhra Pradesh', 'Hisar': 'Haryana',\n",
    "    'Kochi': 'Kerala', 'Ernakulam': 'Kerala', 'Chikhali': 'Maharashtra',\n",
    "    'Limbdi': 'Gujarat', 'Jajpur': 'Odisha', 'Bhubhaneswar': 'Odisha'\n",
    "}\n",
    "df_stations_clean['state'] = df_stations_clean['state'].replace(state_cleaning_map)\n",
    "\n",
    "# Standardize remaining names (e.g., \"TAMIL NADU\" -> \"Tamil Nadu\")\n",
    "df_stations_clean['state'] = df_stations_clean['state'].str.title()\n",
    "# Consolidate 'Delhi Ncr' and 'Andhra pradesh'\n",
    "df_stations_clean['state'] = df_stations_clean['state'].replace({\n",
    "    'Andhra Pradesh': 'Andhra Pradesh',\n",
    "    'Delhi Ncr': 'Delhi'\n",
    "})\n",
    "\n",
    "# --- 5. Final Drops ---\n",
    "df_stations_clean = df_stations_clean.dropna(subset=['type'])\n",
    "df_stations_clean = df_stations_clean.drop(columns=['address'])\n",
    "\n",
    "print(f\"--- Success: 'df_stations_clean' created with {len(df_stations_clean)} rows. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Cleaning 'Electric Vehicle Trip...csv' ---\n",
      "--- Success: 'df_trip_clean' created with 9620 rows. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Cleaning 'Electric Vehicle Trip...csv' ---\")\n",
    "\n",
    "# --- 1. Load Trip Data (with fixed URL) ---\n",
    "trip_data_url = 'https://raw.githubusercontent.com/JBahulika/AI-Driven-EV-Charging-and-Route-Optimization/main/Data/Electric%2520Vehicle%2520Trip%2520Energy%2520Consumption%2520Data.csv'\n",
    "df_trip = pd.read_csv(trip_data_url)\n",
    "\n",
    "# --- 2. Clean Column Names ---\n",
    "new_column_names = {\n",
    "    'Trip Energy Consumption': 'trip_energy_kwh', 'Vehicle ID': 'vehicle_id',\n",
    "    'Trip Distance': 'trip_distance_km', 'Time of Day': 'time_of_day_24h',\n",
    "    'Day of the Week': 'day_of_week', 'Longitude': 'longitude', 'Latitude': 'latitude',\n",
    "    'Speed': 'speed_kmh', 'Current': 'current_a', 'Total Voltage': 'voltage_v',\n",
    "    'Maximum Cell Temperature of Battery': 'temp_batt_max_c',\n",
    "    'Minimum Cell Temperature of Battery': 'temp_batt_min_c',\n",
    "    'Trip Time Length': 'trip_time_len'\n",
    "}\n",
    "df_trip_clean = df_trip.rename(columns=new_column_names)\n",
    "\n",
    "# --- 3. Filter Outliers ---\n",
    "df_trip_clean = df_trip_clean[(df_trip_clean['latitude'] >= -90) & (df_trip_clean['latitude'] <= 90)]\n",
    "df_trip_clean = df_trip_clean[(df_trip_clean['longitude'] >= -180) & (df_trip_clean['longitude'] <= 180)]\n",
    "df_trip_clean = df_trip_clean[df_trip_clean['speed_kmh'] <= 250]\n",
    "\n",
    "# --- 4. Feature Engineering ---\n",
    "df_trip_clean = df_trip_clean[df_trip_clean['trip_distance_km'] > 0]\n",
    "df_trip_clean['kwh_per_km'] = df_trip_clean['trip_energy_kwh'] / df_trip_clean['trip_distance_km']\n",
    "\n",
    "print(f\"--- Success: 'df_trip_clean' created with {len(df_trip_clean)} rows. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Cleaning 'final_dataset.csv' ---\n",
      "--- Success: 'df_demand_clean' created with 32 rows. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Cleaning 'final_dataset.csv' ---\")\n",
    "\n",
    "# --- 1. Load Demand Data ---\n",
    "final_data_url = 'https://raw.githubusercontent.com/JBahulika/AI-Driven-EV-Charging-and-Route-Optimization/main/Data/final_dataset.csv'\n",
    "df_demand = pd.read_csv(final_data_url)\n",
    "\n",
    "# --- 2. Clean Columns ---\n",
    "if 'Unnamed: 0' in df_demand.columns:\n",
    "    df_demand = df_demand.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "new_names = {\n",
    "    'State Name': 'state_name', 'Two Wheeler': 'two_wheeler', 'Three Wheeler': 'three_wheeler',\n",
    "    'Four Wheeler': 'four_wheeler', 'Goods Vehicles': 'goods_vehicles',\n",
    "    'Public Service Vehicle': 'public_service_vehicle', 'Special Category Vehicles': 'special_category_vehicles',\n",
    "    'Ambulance/Hearses': 'ambulance_hearses', 'Construction Equipment Vehicle': 'construction_equipment_vehicle',\n",
    "    'Other': 'other', 'Grand Total': 'grand_total', 'total-charging-stations': 'total_charging_stations'\n",
    "}\n",
    "df_demand = df_demand.rename(columns=new_names)\n",
    "\n",
    "# --- 3. Handle Missing Values ---\n",
    "# Assume NaN stations = 0 stations\n",
    "df_demand['total_charging_stations'] = df_demand['total_charging_stations'].fillna(0)\n",
    "\n",
    "# --- 4. Feature Engineering ---\n",
    "df_demand['evs_per_station'] = df_demand['grand_total'] / df_demand['total_charging_stations']\n",
    "# Fill 'NaN' (from 0/0) with 0. 'inf' (from x/0) is left as-is.\n",
    "df_demand['evs_per_station'] = df_demand['evs_per_station'].fillna(0)\n",
    "\n",
    "df_demand_clean = df_demand\n",
    "print(f\"--- Success: 'df_demand_clean' created with {len(df_demand_clean)} rows. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Merging datasets ---\n",
      "Merge complete. 175 stations did not have demand data.\n",
      "Starting advanced map generation...\n",
      "--- üèÜ Success: 'ev_demand_heatmap.html' saved. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Merging datasets ---\")\n",
    "\n",
    "# --- 1. Create Merge Keys ---\n",
    "df_stations_to_merge = df_stations_clean.copy()\n",
    "df_demand_to_merge = df_demand_clean.copy()\n",
    "\n",
    "df_stations_to_merge['merge_key'] = df_stations_to_merge['state'].str.lower().str.strip()\n",
    "df_demand_to_merge['merge_key'] = df_demand_to_merge['state_name'].str.lower().str.strip()\n",
    "\n",
    "# --- 2. Perform the Merge ---\n",
    "df_merged_final = pd.merge(\n",
    "    df_stations_to_merge,\n",
    "    df_demand_to_merge,\n",
    "    on='merge_key',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merge complete. {df_merged_final['state_name'].isnull().sum()} stations did not have demand data.\")\n",
    "\n",
    "# --- 3. Build the Advanced Map ---\n",
    "print(\"Starting advanced map generation...\")\n",
    "map_center = [df_merged_final['latitude'].mean(), df_merged_final['longitude'].mean()]\n",
    "m_final = folium.Map(location=map_center, zoom_start=5, tiles='CartoDB positron')\n",
    "\n",
    "# --- 3a. Add Heatmap Layer ---\n",
    "heat_data = df_merged_final[['latitude', 'longitude']].values.tolist()\n",
    "folium.plugins.HeatMap(heat_data, radius=15).add_to(m_final)\n",
    "\n",
    "# --- 3b. Add Smart Markers ---\n",
    "for index, row in df_merged_final.iterrows():\n",
    "    \n",
    "    # Check for missing demand data\n",
    "    if pd.isna(row['evs_per_station']):\n",
    "        demand_text = \"No Demand Data\"\n",
    "        color = 'gray'\n",
    "    else:\n",
    "        # Check for 'infinite' pressure\n",
    "        if np.isinf(row['evs_per_station']):\n",
    "            demand_text = \"Extremely High (No Stations)\"\n",
    "            color = 'red'\n",
    "        else:\n",
    "            demand_text = f\"{row['evs_per_station']:.0f} EVs per Station\"\n",
    "            # Color-code normal markers\n",
    "            if row['evs_per_station'] > 1000:\n",
    "                color = 'orange'\n",
    "            else:\n",
    "                color = 'green'\n",
    "\n",
    "    popup_text = f\"\"\"\n",
    "    <b>Name:</b> {row['name']}<br>\n",
    "    <b>City:</b> {row['city']}<br>\n",
    "    <b>State:</b> {row['state']}<hr>\n",
    "    <b>State Demand:</b> {demand_text}\n",
    "    \"\"\"\n",
    "    popup = folium.Popup(popup_text, max_width=300)\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=popup,\n",
    "        tooltip=row['name'],\n",
    "        icon=folium.Icon(color=color, icon='bolt', prefix='fa')\n",
    "    ).add_to(m_final)\n",
    "\n",
    "# --- 4. Save the Map ---\n",
    "final_map_filename = 'ev_demand_heatmap.html'\n",
    "m_final.save(final_map_filename)\n",
    "\n",
    "print(f\"--- üèÜ Success: 'ev_demand_heatmap.html' saved. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Engineering features for energy model ---\n",
      "Training energy model (rf_v2)...\n",
      "--- üèÜ Success: Energy model 'rf_v2' is trained. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Engineering features for energy model ---\")\n",
    "\n",
    "# --- 1. Engineer Features ---\n",
    "df_engineered = df_trip_clean.copy()\n",
    "df_engineered['temp_diff'] = df_engineered['temp_batt_max_c'] - df_engineered['temp_batt_min_c']\n",
    "bins = [-1, 6, 12, 18, 24]\n",
    "labels = ['Night', 'Morning', 'Afternoon', 'Evening']\n",
    "df_engineered['time_of_day_bin'] = pd.cut(df_engineered['time_of_day_24h'], bins=bins, labels=labels, right=True)\n",
    "df_engineered = pd.get_dummies(df_engineered, columns=['time_of_day_bin'], drop_first=True)\n",
    "\n",
    "# --- 2. Define Features (X) and Target (y) ---\n",
    "new_feature_columns = [\n",
    "    'day_of_week', 'speed_kmh', 'current_a', 'voltage_v', 'temp_batt_max_c', \n",
    "    'temp_batt_min_c', 'temp_diff', 'time_of_day_bin_Morning', \n",
    "    'time_of_day_bin_Afternoon', 'time_of_day_bin_Evening'\n",
    "]\n",
    "target_column = 'kwh_per_km'\n",
    "\n",
    "X = df_engineered[new_feature_columns]\n",
    "y = df_engineered[target_column]\n",
    "\n",
    "# --- 3. Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 4. Train Model ---\n",
    "print(\"Training energy model (rf_v2)...\")\n",
    "rf_v2 = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_v2.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- üèÜ Success: Energy model 'rf_v2' is trained. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Evaluating energy model 'rf_v2' ---\n",
      "\n",
      "========================================\n",
      "\n",
      "--- üìà MODEL PERFORMANCE REPORT ---\n",
      "R-squared (R¬≤):     0.2569\n",
      "Mean Absolute Error (MAE): 0.0410 kwh/km\n",
      "Root Mean Squared Error (RMSE): 0.0587 kwh/km\n",
      "(Context: Average value is 0.2187 kwh/km)\n",
      "========================================\n",
      "\n",
      "--- üèÜ Success: Energy model saved as 'energy_model.joblib' ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Evaluating energy model 'rf_v2' ---\")\n",
    "\n",
    "# --- 1. Make Predictions ---\n",
    "y_predictions = rf_v2.predict(X_test)\n",
    "\n",
    "# --- 2. Calculate Metrics ---\n",
    "r2 = r2_score(y_test, y_predictions)\n",
    "mae = mean_absolute_error(y_test, y_predictions)\n",
    "mse = mean_squared_error(y_test, y_predictions)\n",
    "rmse = np.sqrt(mse) # Fix for older sklearn versions\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "print(\"--- üìà MODEL PERFORMANCE REPORT ---\")\n",
    "print(f\"R-squared (R¬≤):     {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} kwh/km\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f} kwh/km\")\n",
    "print(f\"(Context: Average value is {y_test.mean():.4f} kwh/km)\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# --- 3. Save the Model ---\n",
    "model_filename = 'energy_model.joblib'\n",
    "joblib.dump(rf_v2, model_filename)\n",
    "print(f\"--- üèÜ Success: Energy model saved as '{model_filename}' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Defining Reinforcement Learning Environment ---\n",
      "--- üèÜ Success: 'ChargingStationEnv' class defined. ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Defining Reinforcement Learning Environment ---\")\n",
    "\n",
    "class ChargingStationEnv:\n",
    "    def __init__(self):\n",
    "        # 1. ACTIONS: 0=Low, 1=Medium, 2=High\n",
    "        self.action_prices = {0: 10, 1: 15, 2: 20}\n",
    "        self.action_space_size = len(self.action_prices)\n",
    "\n",
    "        # 2. STATES: 4 Time Bins x 3 Occupancy Levels = 12 States\n",
    "        self.time_bins = ['Night', 'Morning', 'Afternoon', 'Evening']\n",
    "        self.occupancy_levels = ['Low', 'Medium', 'High']\n",
    "        self.state_space_size = len(self.time_bins) * len(self.occupancy_levels)\n",
    "\n",
    "        # 3. ENVIRONMENT RULES\n",
    "        self.demand_prob_schedule = [\n",
    "            0.1, 0.1, 0.1, 0.1, 0.2, 0.3, # 00:00 - 05:00 (Night)\n",
    "            0.5, 0.7, 0.8, 0.6, 0.5, 0.4, # 06:00 - 11:00 (Morning)\n",
    "            0.5, 0.6, 0.7, 0.8, 0.9, 0.9, # 12:00 - 17:00 (Afternoon)\n",
    "            1.0, 1.0, 0.9, 0.8, 0.5, 0.2  # 18:00 - 23:00 (Evening)\n",
    "        ]\n",
    "        self.occupancy_schedule = [\n",
    "            'Low', 'Low', 'Low', 'Low', 'Low', 'Low',       # Night\n",
    "            'Medium', 'Medium', 'High', 'High', 'Medium', 'Medium', # Morning\n",
    "            'Medium', 'High', 'High', 'High', 'High', 'High', # Afternoon\n",
    "            'High', 'High', 'High', 'Medium', 'Medium', 'Low'  # Evening\n",
    "        ]\n",
    "        self.current_hour = 0\n",
    "\n",
    "    def _get_state(self):\n",
    "        if 0 <= self.current_hour <= 5: time_bin_index = 0\n",
    "        elif 6 <= self.current_hour <= 11: time_bin_index = 1\n",
    "        elif 12 <= self.current_hour <= 17: time_bin_index = 2\n",
    "        else: time_bin_index = 3\n",
    "\n",
    "        occupancy = self.occupancy_schedule[self.current_hour]\n",
    "        if occupancy == 'Low': occupancy_index = 0\n",
    "        elif occupancy == 'Medium': occupancy_index = 1\n",
    "        else: occupancy_index = 2\n",
    "            \n",
    "        return time_bin_index * len(self.occupancy_levels) + occupancy_index\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_hour = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        price = self.action_prices[action]\n",
    "        current_state_index = self._get_state()\n",
    "        time_bin = self.time_bins[current_state_index // len(self.occupancy_levels)]\n",
    "        occupancy = self.occupancy_levels[current_state_index % len(self.occupancy_levels)]\n",
    "\n",
    "        reward = 0\n",
    "        customer_arrives = (random.random() < self.demand_prob_schedule[self.current_hour])\n",
    "\n",
    "        if customer_arrives:\n",
    "            customer_stays = False\n",
    "            if time_bin == 'Night' or occupancy == 'Low':\n",
    "                if price <= 15: customer_stays = True\n",
    "            elif time_bin == 'Evening' and occupancy == 'High':\n",
    "                customer_stays = True\n",
    "            else:\n",
    "                if price <= 15: customer_stays = (random.random() < 0.9)\n",
    "                else: customer_stays = (random.random() < 0.5)\n",
    "\n",
    "            if customer_stays: reward = price\n",
    "            else: reward = -5 # Penalty for lost sale\n",
    "        \n",
    "        self.current_hour += 1\n",
    "        done = (self.current_hour == 24)\n",
    "        new_state = self._get_state() if not done else None\n",
    "        \n",
    "        return new_state, reward, done\n",
    "\n",
    "print(\"--- üèÜ Success: 'ChargingStationEnv' class defined. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Starting: Initializing Q-Learning Agent ---\n",
      "Running 50000 training episodes (days)...\n",
      "--- üèÜ Training Complete! ---\n",
      "\n",
      "========================================\n",
      "\n",
      "--- FINAL Q-TABLE (The AI 'Brain') ---\n",
      "[[153.09 159.45 150.12]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [141.33 159.64 144.92]\n",
      " [164.44 173.48 162.06]\n",
      " [  0.     0.     0.  ]\n",
      " [109.88 118.45 107.42]\n",
      " [107.81 114.73 105.41]\n",
      " [  0.09   1.24  -1.02]\n",
      " [ 10.33  18.86   9.14]\n",
      " [ 63.54  61.49  71.54]]\n",
      "\n",
      "========================================\n",
      "\n",
      "--- üèÜ Success: Pricing model saved as 'pricing_model_q_table.npy' ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Starting: Initializing Q-Learning Agent ---\")\n",
    "env = ChargingStationEnv()\n",
    "\n",
    "# --- 1. Initialize Q-Table and Hyperparameters ---\n",
    "q_table = np.zeros((env.state_space_size, env.action_space_size))\n",
    "total_episodes = 50000\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.99\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.0001\n",
    "\n",
    "print(f\"Running {total_episodes} training episodes (days)...\")\n",
    "\n",
    "# --- 2. Run the Training Loop ---\n",
    "for episode in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Explore vs. Exploit\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = np.random.randint(0, env.action_space_size)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state, :])\n",
    "\n",
    "        # Take action\n",
    "        new_state, reward, done = env.step(action)\n",
    "        \n",
    "        # Q-Learning Formula\n",
    "        if not done:\n",
    "            q_table[state, action] = q_table[state, action] + learning_rate * (\n",
    "                reward + discount_rate * np.max(q_table[new_state, :]) - q_table[state, action]\n",
    "            )\n",
    "        else:\n",
    "            q_table[state, action] = q_table[state, action] + learning_rate * (reward - q_table[state, action])\n",
    "\n",
    "        state = new_state\n",
    "        \n",
    "    # Decay Epsilon\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "\n",
    "print(\"--- üèÜ Training Complete! ---\")\n",
    "\n",
    "# --- 3. Print and Save the Final \"AI Brain\" (The Q-Table) ---\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "print(\"--- FINAL Q-TABLE (The AI 'Brain') ---\")\n",
    "np.set_printoptions(precision=2, suppress=True) \n",
    "print(q_table)\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# --- 4. Save the Q-Table ---\n",
    "q_table_filename = 'pricing_model_q_table.npy'\n",
    "np.save(q_table_filename, q_table)\n",
    "print(f\"--- üèÜ Success: Pricing model saved as '{q_table_filename}' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading models back from files ---\n",
      "Energy model 'energy_model.joblib' loaded successfully.\n",
      "Pricing model 'pricing_model_q_table.npy' loaded successfully.\n",
      "\n",
      "--- Energy Model Prediction Example ---\n",
      "Predicted energy use: 0.2221 kwh/km\n",
      "\n",
      "--- Pricing Model Prediction Example ---\n",
      "For State 11 (Evening, High):\n",
      "  Action values are: [63.54 61.49 71.54]\n",
      "  The AI chooses: Index 2 -> High Price\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Loading models back from files ---\")\n",
    "\n",
    "# --- 1a. Load the Energy Model ---\n",
    "try:\n",
    "    energy_model = joblib.load('energy_model.joblib')\n",
    "    print(\"Energy model 'energy_model.joblib' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading energy model: {e}\")\n",
    "\n",
    "# --- 1b. Load the Pricing Model ---\n",
    "try:\n",
    "    pricing_model = np.load('pricing_model_q_table.npy')\n",
    "    print(\"Pricing model 'pricing_model_q_table.npy' loaded successfully.\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pricing model: {e}\")\n",
    "\n",
    "\n",
    "# --- 2. Example: Use the Energy Model ---\n",
    "# Let's create a *hypothetical* trip\n",
    "# We need to provide all 10 features our 'rf_v2' model was trained on\n",
    "hypothetical_trip = [\n",
    "    5,      # 'day_of_week' (e.g., Friday)\n",
    "    60,     # 'speed_kmh'\n",
    "    -10,    # 'current_a' (Regen braking)\n",
    "    350,    # 'voltage_v'\n",
    "    30,     # 'temp_batt_max_c'\n",
    "    28,     # 'temp_batt_min_c'\n",
    "    2,      # 'temp_diff' (30 - 28)\n",
    "    0,      # 'time_of_day_bin_Morning' (0=False)\n",
    "    1,      # 'time_of_day_bin_Afternoon' (1=True)\n",
    "    0       # 'time_of_day_bin_Evening' (0=False)\n",
    "]\n",
    "# Convert to numpy array for the model\n",
    "trip_data = np.array([hypothetical_trip])\n",
    "\n",
    "# Make prediction\n",
    "predicted_kwh_per_km = energy_model.predict(trip_data)\n",
    "print(\"--- Energy Model Prediction Example ---\")\n",
    "print(f\"Predicted energy use: {predicted_kwh_per_km[0]:.4f} kwh/km\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Example: Use the Pricing Model ---\n",
    "# What price should we set at 'Evening, High Occupancy' (State 11)?\n",
    "state_to_check = 11\n",
    "\n",
    "# Look up the action values for that state\n",
    "action_values = pricing_model[state_to_check]\n",
    "# Find the index of the highest value\n",
    "best_action_index = np.argmax(action_values)\n",
    "\n",
    "price_map = {0: 'Low Price', 1: 'Medium Price', 2: 'High Price'}\n",
    "\n",
    "print(\"--- Pricing Model Prediction Example ---\")\n",
    "print(f\"For State {state_to_check} (Evening, High):\")\n",
    "print(f\"  Action values are: {action_values}\")\n",
    "print(f\"  The AI chooses: Index {best_action_index} -> {price_map[best_action_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
